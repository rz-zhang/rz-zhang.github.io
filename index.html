<html style="width: 100%; max-width: 1080px; margin-right: auto; margin-left: auto">
<head>
<title> Rongzhi Zhang</title>
<link rel="icon" href="/img/rongzhi-favicon.png" type="image/png">
</head>

<table cellspacing="10" border="0" cellpadding="1">
<tr>
<td>
<h1 class="title"> <center>Rongzhi Zhang</center> </h1>
<table border="0" cellpadding="0">
<tbody> <tr>
<td valign="top" style="min-width:140px;">
<img src="Portrait_Rongzhi.JPG" width="220" style="float:left; margin:0pt 30pt 0pt 0pt;" > 
</td>
<td valign="top">
<!-- <b>M.S. Student</b><br> -->
<strong> Ph.D. Student</strong><br>
<a href="https://ml.gatech.edu/">Machine Learning Center</a><br>
<a href="https://cse.gatech.edu">School of Computational Science and Engineering</a><br>
<!-- <a href="https://www.cc.gatech.edu">College of Computing</a><br> -->
<a href="https://www.gatech.edu">Georgia Institute of Technology</a><br><br>
<strong>Office</strong>: CODA E1317<br>
<strong>Address</strong>: 756 W Peachtree St NW, Atlanta, GA 30308<br>
<strong>Email</strong>: <a href="mailto:rongzhi.zhang@gatech.edu">rongzhi.zhang@gatech.edu</a><br>
<b>External Links</b>:<br>
<div style="height:2px; width:1px;">  </div>
<!-- <a href="https://scholar.google.com/citations?hl=en&user=jHgmQEIAAAAJ"><strong>[Google Scholar]</strong></a>
<a href="https://www.linkedin.com/in/rongzhi-zhang-a20460178/"><strong>[LinkedIn]</strong></a>
<a href="CV_Nov20.pdf"><strong>[CV]</strong></a> -->
<a href="https://twitter.com/rongzhi_zhang"><img src="img/twitter.png" alt="twitter" height="38px" style="vertical-align:middle" /></a>  
        <a href="https://scholar.google.com/citations?hl=en&user=jHgmQEIAAAAJ"><img src="img/googlescholar.png" alt="google scholar" height="35px" style="vertical-align:middle" /></a>  
        <a href="https://github.com/rz-zhang"><img src="img/github.png" alt="github" height="35px" style="vertical-align:middle" /></a>  
        <a href="https://www.linkedin.com/in/rongzhi-zhang-a20460178/"><img src="img/linkedin.png" alt="linkedin" height="35px" style="vertical-align:middle" /></a>
</td>
</tr>
</tbody>
</table>

</td>
</table>

<!--<td> -->
<!-- <a href="#bio"><strong>[Biography]</strong></a>   -->
<!--p-->
<!-- <a href="https://scholar.google.com/citations?user=zQ3Jh6UAAAAJ&hl=en"><strong>[Google Scholar]</strong></a>
<a href="https://www.linkedin.com/in/rongzhi-zhang-a20460178/"><strong>[LinkedIn]</strong></a>
<a href="CV.pdf"><strong>[CV]</strong></a>  -->
<!-- <a href="Resume_1page.pdf"><strong>[Resume]</strong></a>  -->
<!-- <a href="#education"><strong>[Education]</strong></a> -->
<!-- <a href="#publications"><strong>[Publications]</strong></a> -->

<!--p-->
<!--a href="https://scholar.google.com/citations?user=zQ3Jh6UAAAAJ&hl=en">
        <strong>[Google Scholar]</strong></a> 
<a href="https://www.linkedin.com/in/yue-yu-b75553115/"><strong>[Linkedin]</strong></a>

<a href="https://github.com/yueyu1030"><strong>[Github]</strong></a>

<a href=https://www.instagram.com/yue.yu.8/><strong>[Instagram]</strong></a--><!--p-->

</p>
<hr>
<h2><a name ="bio">Biography</a></h2>
I am a final-year Ph.D. student in the Machine Learning Center at Georgia Tech <a href="http://ml.gatech.edu/">(ML@GT)</a>, advised by <a href="http://chaozhang.org/">Prof. Chao Zhang</a>. I am also fortunate to work with <a href="https://scholar.google.com/citations?user=Xl4E0CsAAAAJ">Prof. Le Song</a>. My research interest primarily lies in model efficiency and data efficiency of language models. Beyond academia, I've spent several fantastic research internships at Google Research, Microsoft Azure AI, and Amazon Store Foundational AI.  <p>
Before that, I obtained my bachelor's degree from <a href="http://www.zju.edu.cn/english/">Zhejiang University</a>, and I spent my senior year as a visiting student researcher at <a href="https://hms.harvard.edu/">Harvard Medical School</a>.

<p> 
<hr>
<h2><a name ="news">News</a></h2>
<ul class="org-ul">
<li>[--- Top ---] <strong>Join the Journey</strong>: I am currently diving into exciting projects about Large Language Models (LLM), <strong>seeking collaborators/mentees</strong> with expertise in this field! Computational resources and preliminary validated ideas provided. Contact me if interested in collaboration!
<li>[Sept.  2024] One paper accepted to <a href= https://neurips.cc/>NeurIPS'24</a>, we proposed a test-time LLM alignment approach via representation editing. 
<li>[July  2024] One paper accepted to the 1st <a href= https://colmweb.org/>COLM</a>, we presented a teacher-student framework to improve LLM reasoning capability via principle discovery.
<li>[May  2024] One paper accepted to <a href= https://kdd.org/kdd2024/>KDD'24</a>, we proposed a novel knowledge distillation objective for LLMs by perturbing the standard KL loss.
<li>[May  2024] Two papers accepted to <a href= https://2024.aclweb.org/>ACL'24</a> (findings), discussing 1) preference-based distillation for LLMs and 2) attributed data synthesis via LLMs.  
<li>[May 2024] I will join <a href= https://www.aboutamazon.com/news/retail/amazon-rufus>Amazon </a> (Rufus Team) as a research intern in Summer 2024, exploring preference learning for LLM alignment.</li>
<li>[Dec. 2023] I will join <a href= https://www.microsoft.com/en-us/research/>Microsoft Research</a> as a research intern in Spring 2024, exploring KV Cache compression for LLMs.</li>
<li>[May  2023] One paper accepted to <a href= https://kdd.org/kdd2023/>KDD'23</a>, we proposed an iterative and adaptive framework for boosting in weakly-supervised learning settings.
<li>[May  2023] Two papers accepted to <a href= https://2023.aclweb.org/>ACL'23</a>, discussing cold-start data selection for few-shot LM finetuning and retrieval enhanced LM.
<li>[Mar. 2023] I will be back to <a href= https://research.google/>Google Reseach</a> NYC as a student researcher this summer.</li>
<!-- <li>[May  2022] One paper accepted to <a href= https://kdd.org/kdd2022/>KDD'22</a>, discussing adaptive multi-view rule discovery.
<li>[Apr. 2022] One paper accepted to  <a href= https://2022.naacl.org/>NAACL'22</a>, discussing uncertainty-based active self-training.</li>
<li>[Mar. 2022] I will join <a href= https://research.google/>Google Reseach</a> as a student researcher this summer, see you in New York City.</li>
<li>[Feb. 2022] One paper accepted by <a href= https://www.2022.aclweb.org/>ACL'22</a>, discussing interactive weakly-supervised learning.</li> -->
        
<p>
</ul>
<hr>
<!-- <a name="education"><h2> Education </h2></a> 
<ul>
    <li> <a href="https://www.gatech.edu">Georgia Institute of Technology</a>, Atlanta, <i>Aug. 2019 - Present</i><br> 
            <img src="gatech.jpg" width="210" style="float:right; position:relative; right:30px; top:-30px;" > 
        Ph.D. in Machine Learning<br>
        M.S. in Electrical and Computer Engineering (<i>May 2021</i>)<br><br><br>
    </li>
    <li> <a href="http://www.zju.edu.cn/english/">Zhejiang University</a>, Hangzhou, <i>Aug. 2015 - June 2019</i><br> 
            <img src="zju_logo.png" width="220" style="float:right; position:relative; right:30px; top:-50px;" > 
        B.Eng. in Measurement Control Technology and Instruments<br><br><br>
    </li>
    <li> <a href="https://hms.harvard.edu/">Harvard Medical School</a>, Boston, <i>Sep. 2018 - May 2019</i><br> 
            <img src="hms_logo.png" width="220" style="float:right; position:relative; right:30px; top:-70px;" >
        Visiting Student Researcher in Neural System Group<br><br><br>
    </li>
</ul> -->

        <style>
    .education-list {
        list-style: none;
        padding: 0;
    }

    .education-item {
        display: flex;
        justify-content: space-between;
        align-items: center; 
        margin-bottom: 20px;
    }

    .education-item img {
        width: 220px; 
        margin-left: 30px; 
    }
</style>

<a name="education"><h2> Education </h2></a> 
<ul class="education-list">
    <li class="education-item"> 
        <div>
            <a href="https://www.gatech.edu">Georgia Institute of Technology</a>, Atlanta, <i>Aug. 2019 - Present</i><br>
            Ph.D. in Machine Learning<br>
            M.S. in Electrical and Computer Engineering (<i>May 2021</i>)
        </div>
        <img src="gatech.jpg">
    </li>
    <li class="education-item">
        <div>
            <a href="http://www.zju.edu.cn/english/">Zhejiang University</a>, Hangzhou, <i>Aug. 2015 - June 2019</i><br>
            B.Eng. in Measurement Control Technology and Instruments
        </div>
        <img src="zju_logo.png">
    </li>
    <li class="education-item">
        <div>
            <a href="https://hms.harvard.edu/">Harvard Medical School</a>, Boston, <i>Sep. 2018 - May 2019</i><br>
            Visiting Student Researcher in Neural System Group
        </div>
        <img src="hms_logo.png">
    </li>
</ul>

        
<hr>
<h2><a name ="research">Research</a></h2>
My research focuses on advancing language models in three key aspects:
<ul> 
<li> <b>Model Efficiency</b>: Progressive KV cache compression (<a href="https://arxiv.org/abs/2410.03111">Preprint</a>); Knowledge distillation (<a href="https://dl.acm.org/doi/pdf/10.1145/3637528.3671851">KDD'24</a>, <a href="https://aclanthology.org/2024.findings-acl.923.pdf">ACL'24</a>, <a href="https://arxiv.org/abs/2401.13849">COLM'24</a>)
</li>
<li> <b>Model Alignment</b>: Robust reward modeling (<a href="">Preprint</a>); Test-time alignment (<a href="https://arxiv.org/abs/2406.05954">NeurIPS'24</a>)
</li>
<li> <b>Data-centric Approach</b>: Data selection and weak supervision (<a href="https://aclanthology.org/2022.acl-long.55.pdf">ACL'22</a>, <a href="https://arxiv.org/abs/2209.06995">ACL'23</a>,  <a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599417">KDD'23</a>)
</ul>



<hr>
<h2><a name ="preprints">Preprints</a> </h2>

<!--  <li>
<b>Rongzhi Zhang</b>, Kuan Wang, Liyuan Liu, Shuohang Wang, Hao Cheng, Chao Zhang and Yelong Shen. <br>
<a href="https://arxiv.org/abs/2410.03111"><strong>LoRC: Low-Rank Compression for LLMs KV Cache with a Progressive Compression Strategy
</strong></a><br>
</li> <p>  -->

<li>
<b>Rongzhi Zhang</b>, Chenwei Zhang, Xinyang Zhang, Liang Qiu, Yuchen Zhuang, Qingru Zhang, Hyokun Yun, Tuo Zhao, Chao Zhang. <br>
<a href=""><strong>Quality-Aware Preference Data Weighting for Generalizable Reward Model
</strong></a><br>
</li> <p> 

<li>
<b>Rongzhi Zhang</b>, Yuzhao Heng, Yixiao Li, Alexander Bukharin, Tuo Zhao, Chao Zhang. <br>
<a href=""><strong>Strength-Controlled Preference Data Synthesis for Complimentary Rewarding
</strong></a><br>
</li> <p> 

<hr>
<h2><a name ="publication">Publications</a> </h2>
<!-- 
<h3>Preprints</h3>

<li>
Yue Yu, <b>Rongzhi Zhang</b>, Ran Xu, Jieyu Zhang, Jiaming Shen and Chao Zhang. <br>
<a href="https://arxiv.org/pdf/2209.06995.pdf"><strong>Cold-Start Data Selection for Few-shot Language Model Fine-tuning:
A Prompt-Based Uncertainty Propagation Approach
</strong></a><br>
Available on arXiv, 2022.<br>
<a href="bib/patron.txt">[BibTex]</a> <a href="https://arxiv.org/pdf/2209.06995.pdf">[arXiv]</a>
</li> <p>    

<h3>Conference</h3> -->
<!-- <ul class="org-ul"> -->
<li>
<b>Rongzhi Zhang</b>, Kuan Wang, Liyuan Liu, Shuohang Wang, Hao Cheng, Chao Zhang and Yelong Shen. <br>
<a href="https://arxiv.org/abs/2410.03111"><strong>LoRC: Low-Rank Compression for LLMs KV Cache with a Progressive Compression Strategy
</strong></a><br>
In <i>Machine Learning and Compression Workshop of Annual Conference on Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2024.<br>
</li> <p>   

<li>
Lingkai Kong, Haorui Wang, Wenhao Mu, Yuanqi Du, Yuchen Zhuang, Yifei Zhou, Yue Song, <b>Rongzhi Zhang</b>, Kai Wang and Chao Zhang. <br>
<a href="https://arxiv.org/abs/2406.05954"><strong>Aligning Large Language Models with Representation Editing: A Control Perspective
</strong></a><br>
In <i>Annual Conference on Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2024.<br>
</li> <p>   
        
<li>
Haorui Wang, <b>Rongzhi Zhang</b>, Yinghao Li, Lingkai Kong, Yuchen Zhuang, Xiusi Chen and Chao Zhang. <br>
<a href="https://arxiv.org/abs/2401.13849"><strong>TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance
</strong></a><br>
In the 1st <i>Conference on Language Modeling</i> (<b>COLM</b>), 2024.<br>
</li> <p>   

<li>
<b>Rongzhi Zhang</b>, Jiaming Shen, Tianqi Liu, Jialu Liu, Michael Bendersky, Marc Najork and Chao Zhang. <br>
<a href="https://dl.acm.org/doi/pdf/10.1145/3637528.3671851"><strong>Knowledge Distillation with Perturbed Loss: From a Vanilla Teacher to a Proxy Teacher
</strong></a><br>
In <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i> (<b>KDD</b>), 2024.<br>
<!-- <a href="bib/ptloss.txt">[BibTex]</a> <a href="https://arxiv.org/pdf/2305.05010.pdf">[arXiv]</a> -->
</li> <p>   

<li>
<b>Rongzhi Zhang</b>, Jiaming Shen, Tianqi Liu, Haorui Wang, Zhen Qin, Feng Han, Jialu Liu, Simon Baumgartner, Michael Bendersky and Chao Zhang.  <br>
<a href="https://aclanthology.org/2024.findings-acl.923.pdf"><strong>PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs
</strong></a><br>
In <i>Findings of Annual Meeting of the Association for Computational Linguistics</i> (<b>ACL</b>), 2024.<br>
</li> <p>   

<li>
Yuzhao Heng, Chunyuan Deng, Yitong Li, Yue Yu, Yinghao Li, <b>Rongzhi Zhang</b>, Chao Zhang <br>
<a href="https://arxiv.org/pdf/2403.11103"><strong>ProgGen: Generating Named Entity Recognition Datasets Step-by-step with Self-Reflexive Large Language Models
</strong></a><br>
In <i>Findings of Annual Meeting of the Association for Computational Linguistics</i> (<b>ACL</b>), 2024.<br>
<!-- <a href="bib/prog_gen">[BibTex]</a> <a href="https://arxiv.org/pdf/2403.11103">[arXiv]</a> -->
</li> <p>   
        
<li>
<b>Rongzhi Zhang</b>, Yue Yu, Jiaming Shen, Xiquan Cui and Chao Zhang. <br>
<a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599417"><strong>Local Boosting for Weakly-Supervised Learning
</strong></a><br>
In <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i> (<b>KDD</b>), 2023.<br>
<!-- <a href="bib/localboost.txt">[BibTex]</a> <a href="https://arxiv.org/pdf/2306.02859.pdf">[arXiv]</a> -->
</li> <p>  

<li>
Yue Yu, <b>Rongzhi Zhang</b>, Ran Xu, Jieyu Zhang, Jiaming Shen and Chao Zhang. <br>
<a href="https://arxiv.org/abs/2209.06995"><strong>Cold-Start Data Selection for Few-shot Language Model Fine-tuning:
A Prompt-Based Uncertainty Propagation Approach
</strong></a><br>
In <i>Annual Meeting of the Association for Computational Linguistics</i> (<b>ACL</b>), 2023.<br>
<!-- <a href="bib/patron.txt">[BibTex]</a> <a href="https://arxiv.org/pdf/2209.06995.pdf">[arXiv]</a> -->
</li> <p>   
        
<li>
Yue Yu, Yuchen Zhuang, <b>Rongzhi Zhang</b>, Yu Meng, Jiaming Shen and Chao Zhang. <br>
<a href="https://arxiv.org/abs/2305.10703"><strong>Zero-Shot Text Classification by Training Data Creation with Progressive Dense Retrieval
</strong></a><br>
In <i> Findings of Annual Meeting of the Association for Computational Linguistics</i> (<b>ACL</b>), 2023.<br>
<!-- <a href="bib/regen.txt">[BibTex]</a> <a href="https://arxiv.org/pdf/2305.10703.pdf">[arXiv]</a> -->
</li> <p>     
        
<li>
<b>Rongzhi Zhang</b>, Yue Yu, Shetty Pranav, Le Song and Chao Zhang.<br>
<a href="https://aclanthology.org/2022.acl-long.55.pdf"><strong>PRBoost: Prompt-Based Rule Discovery and Boosting for Interactive Weakly-Supervised Learning </strong></a><br>
In <i>Annual Meeting of the Association for Computational Linguistics</i> (<b>ACL</b>), 2022.<br>
<!-- <a href="bib/prboost.txt">[BibTex]</a> <a href="https://arxiv.org/abs/2203.09735">[arXiv]</a> -->
</li> <p>       
        
<li>
<b>Rongzhi Zhang</b>, Rebecca West, Xiquan Cui and Chao Zhang.<br>
<a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539208"><strong>Adaptive Multi-view Rule Discovery for Weakly-Supervised Compatible Products Prediction</strong></a><br>
In <i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i> (<b>KDD</b>), 2022.<br>
<!-- <a href="bib/amrule.txt">[BibTex]</a> <a href="https://arxiv.org/pdf/2206.13749.pdf">[arXiv]</a> -->
</li> <p>  
        
<li> 
Yue Yu, Lingkai Kong, Jieyu Zhang, <b>Rongzhi Zhang</b> and Chao Zhang.<br>
<a href="https://arxiv.org/pdf/2112.08787.pdf"><strong>AcTune: Uncertainty-Aware Active Self-Training for Active Fine-Tuning of Pretrained Language Models </strong></a><br>
In <i>Annual Conference of the North American Chapter of the Association for Computational Linguistics</i> (<b>NAACL</b>), 2022.<br>
<!-- <a href="bib/atm.txt">[BibTex]</a> <a href="https://arxiv.org/pdf/2112.08787.pdf">[arXiv]</a> -->
</li> <p>
        
<li> <b>Rongzhi Zhang</b>, Yue Yu and Chao Zhang.<br>
<a href="pdf/emnlp20_SeqMix.pdf"><strong>SeqMix: Augmenting Active Sequence Labeling via Sequence Mixup</strong></a><br>
In <i>Proceedings of the Conference on Empirical Methods in Natural Language Processing </i> (<b>EMNLP</b>), 2020.<br>
<!-- <a href="bib/seqmix.txt">[BibTex]</a> <a href="slides/EMNLP20_SeqMix_Slides.pdf">[Slides]</a> -->
</li> <p>
        

<!-- <hr>
<h2><a name ="news">News</a></h2>
<ul class="org-ul">
<li><strong>[Sep. 2020]</strong> One paper accepted to EMNLP'20, discussing augmenting sequence labeling in low-resource settings.
<li><strong>[Aug. 2020]</strong> Started my position, Teaching Assistant of <a href="https://mahdi-roozbahani.github.io/CS46417641-fall2020/#">CS 7641-Machine Learning</a> at Georgia Tech.</li>
<li><strong>[June 2019]</strong> Received my bachlor's degree in engineering from Zhejiang University with outstanding graduate honor.</li>
<li><strong>[May 2019]</strong> Joined in the AI team, <a href="http://www.goodwillcis.com/">GoodWill</a>, Beijing, one of the leading medical data firms in China as a summer intern.
<li><strong>[Sep. 2018]</strong> Started my thesis research as an intern in the <a href="https://bme.mgh.harvard.edu/">Neural System Group</a>, <a href="https://hms.harvard.edu/">Harvard Medical School</a>.</li>
 -->
        
<!--li>Honored to receive the ACM SIGKDD 2019 Dissertation Runner-up Award!</li>
<li>Our monograph <a href="https://www.morganclaypool.com/doi/10.2200/S00903ED1V01Y201902DMK017">Multidimensional Mining of Massive Text Data</a> is published by Morgan &amp; Claypool!</li>
<li>One paper accepted by KDD'19 Research Track as an oral, and two accepted by the Project Showcase Track.</li>
<li>One paper on deep generative modeling accepted by ICML'19.</li>
<li>Try out <a href="https://github.com/yumeng5/WeSTClass">WeSTClass</a> for <a href="papers/2018-cikm-westclass.pdf">weakly-supervised text classification</a>!</li>
<li>Our paper on linear-time trajectory similarity computation is accepted by ICDE'19: up to 100x speedup and supports most similarity measures.</li>
<li>Our paper on <a href="https://dl.acm.org/citation.cfm?id=3264954">semi-supervised deep learning for IoT</a> won the distinguished paper award in IMWUT'18!</li>
<li>Gave a tutorial on <a href="https://shangjingbo1226.github.io/2018-04-21-kdd-tutorial/">multidimensional analysis of text data</a> in KDD'18.</li>
<li>Talked about event detection on <a href="https://grainger.illinois.edu/news/podcasts/">Illinois Innovator Podcast</a>, available on <a href="https://engineering.illinois.edu/news/article/23905">SoundCloud</a> and <a href="https://itunes.apple.com/us/podcast/engineering-at-illinois/id1237376461?mt=2">iTunes</a>.</li>
<li>Check out <a href="http://www.itbusiness.ca/news/tweet-analysis-could-pinpoint-where-to-send-emergency-help-in-disasters-like-harvey/94590">IT Business' report</a> on our event detection work.</li-->

<p>
</ul>
<hr>
<a name="experiences"><h2> Experiences </h2></a> 
<ul>
<li> <strong>Research Intern</strong> | <i>Jan. 2024 - May 2024</i><br>
     <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>, Redmond, WA<br>
        Host:
       <a href="https://sites.google.com/site/shuohangsite">Shuohang Wang</a>,
        <a href="https://liyuanlucasliu.github.io/">Lucas Liu</a>,
       <a href="https://scholar.google.com/citations?user=S6OFEFEAAAAJ">Yelong Shen</a><br>
       <img src="microsoft.png" width="180" style="float:right; position:relative;right:30;top:-50">
        <br><br>
</li>
<li> <strong>Student Researcher</strong> | <i>May 2023 - Dec. 2023</i><br>
     <a href="https://research.google/">Google Research</a>, New York City, NY<br>
        Host:
       <a href="https://mickeysjm.github.io/">Jiaming Shen</a>, 
       <a href="https://scholar.google.com/citations?user=pUKhiMIAAAAJ">Tianqi Liu</a>, 
       <a href="https://jialu.info/">Jialu Liu</a><br>
        <img src="google.png" width="180" style="float:right; position:relative;right:30;top:-60">
        <br><br>
</li>
<li> <strong>Student Researcher</strong> | <i>May 2022 - Dec. 2022</i><br>
     <a href="https://research.google/">Google Research</a>, New York City, NY<br>
         Host:
       <a href="https://mickeysjm.github.io/">Jiaming Shen</a>, 
       <a href="https://scholar.google.com/citations?user=pUKhiMIAAAAJ">Tianqi Liu</a>, 
       <a href="https://scholar.google.com/citations?user=C9mxM5IAAAAJ">Michael Bendersky</a><br>
        <img src="google.png" width="180" style="float:right; position:relative;right:30;top:-55">
        <br><br><br>
</li>
<!-- <li> <strong>Graduate Research Assistant</strong> | <i>Jan. 2021 - Present</i><br>
     Georgia Institute of Technology, Atlanta<br><br>
</li> -->

<!-- <li> <strong>Research Intern</strong> | <i>May 2019 - Aug. 2019</i><br>
     Medical Artificial Intelligence Team, <a href="http://www.goodwillcis.com/">GoodWill Inc.</a>, Beijing <br><br>
</li> -->
<!-- <li> <strong>Research Intern</strong> | <i>July 2018 - Aug. 2018</i> <br>
     Center for Acoustics, Dynamics and Vibration, University of Western Australia, Perth <br>
     Supervisor: <a href="https://scholar.google.com/citations?user=92zEWQUAAAAJ&hl=zh-CN">Prof. Jie Pan</a><br>
</li> -->
</ul>


<hr>
<a name="teaching"><h2> Teaching </h2></a> 
<ul>
<li> <strong>Graduate Teaching Assistant</strong> | <i>Aug. 2023 - Dec. 2023</i><br>
     <a href="http://chaozhang.org/course/cse8803-23f.html">CSE 8803 - Deep Learning for Text Data (Fall 2023)</a>, Georgia Tech<br><br>
</li>
<li> <strong>Graduate Teaching Assistant</strong> | <i>Aug. 2021 - Dec. 2021</i><br>
     <a href="http://chaozhang.org/course/cse8803-21f.html">CSE 8803 - Deep Learning for Text Data (Fall 2021)</a>, Georgia Tech<br><br>
</li>
<li> <strong>Graduate Teaching Assistant</strong> | <i>Aug. 2020 - Dec. 2020</i><br>
     <a href="https://mahdi-roozbahani.github.io/CS46417641-fall2020/#">CS 4641/7641 - Machine Learning (Fall 2020)</a>, Georgia Tech<br><br>
</li>
</ul>


        
<!-- <hr>
<h2><a name="awards">Selected Awards</a></h2>
<ul>
<li>2023 KDD Student Travel Award, ACM SIGKDD
<li>2019 Outstanding Graduate, Zhejiang University
<li>2019 Outstanding Undergrad Thesis, Zhejiang University
<li>2018 Zhejiang Provincial Government Scholarship (Top 3%)
<li>2018 First-class Excellent Undergraduate Scholarship, Zhejiang University (Top 3%) 
<li>2018 First-class Academic Scholarship, Zhejiang University (Top 3%)  
<li>2016 Student Innovation Research Funding, Zhejiang Province
<li>2014 The first prize in the 31st Chinese Physics Olympiad (CPhO)
</ul> -->

<hr>
<h2><a name="service">Academic Service</a></h2>
<ul>
<li> Program Committee / Reviewer: TKDE 2020, 2021; EMNLP 2022; ACL 2022; KDD 2023; NeurIPS 2023, 2024; ACL Rolling Review 2023, 2024; AISTATS 2024; ICLR 2024, 2025.
</ul>

<hr>
<h2><a name="misc">Misc</a></h2>
<ul>
<li> I was a player of Zhejiang University Varsity Men's basketball team, competing in CUBA Division II.
</ul>

<!-- <hr>
Last updated on Jan. 2024.<br><br> -->

<!-- <hr>
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=D3wWXP3Kv3IVhh7fYvW5LWNjVpO4pV7C3XDWg65CCHE&cl=ffffff&w=a"></script><br><br> -->
<div style="height:1px; width:1px;">
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=n&d=Zs3JaM6SBUlUZKURNI-PcsYxht3UbxRANWjAJvQI8tY&co=ffffff&cmo=ffffff&cmn=ffffff'></script>
</div>
</body>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-96343017-1', 'auto');
  ga('send', 'pageview');

</script>
</html>
